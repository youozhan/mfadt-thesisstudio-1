#### Research Method Candidates
* Brainstorming
* Flow Analysis
* Character Profile
* Error Analysis
* Long-Range Forecasts
#### Extended Resources
[Algorithm of Oppression](https://nyupress.org/books/9781479837243/)

> *Algorithm of Oppression* using Google search algorithm as an example, points out that the algorithm is a fundamental invention of computer scientists who are human beings, may not be racist. However, the algorithm clearly reflects the biases and values among a large group, in which minorities can be rarely noticed. The book also mentioned a few key people in the area: Helen Nissenbaum and Lucas Introna have written about how search engine bias information toward the most powerful online; Alejandro Diaz who wrote his dissertation at Standford on sociopolitical bias in Google's product; Kate Crawford and Tarleton Gillespie at Microsoft Research professor of media, culture, communication, and computer science. 

[The Black Box Society](http://www.hup.harvard.edu/catalog.php?isbn=9780674368279)

> *The Black Box Society* asks the question of how secrecy has become so important to industries ranging from Wall Street to Silicon Valley and again emphasizes on the fact that the algorithmic control has gone beyond the money and information and into every aspect of the everyday life. 

[Anatomy of AI](https://anatomyof.ai)
> Kate Crawford from AI Now Institute and Vladan Joler from Share Lab presented this anatomical map of Amazon Echo. Although the system and the interaction can be viewed as simply as a combination of a command plus a response, there are more underneath: chains of resource extraction, human labor, algorithmic processing, and logistics. 

[Visualization for AI Explainability](https://visxai.io)
> Workshop on Visualization for AI Explainability at IEEE VIS provided another example of breaking the black box of algorithms. The goal of this workshop is to use visualization to illustrate how AI techniques work. 

[Publication from Google](https://ai.google/research/pubs/)
> The paper from Google's research team can also be served as a source of explanatory resources. 

[AI system uses transparent, human-like reasoning to solve problems](http://news.mit.edu/2018/mit-lincoln-laboratory-ai-system-solves-problems-through-human-reasoning-0911)
> Meanwhile, a new standard is being set up from the algorithm itself, to make the Artificial Intelligence system use human-like reasoning to solve problems.  

[Experimental evidence of massive-scale emotional contagion through social networks in PNAS](http://www.pnas.org/content/pnas/111/24/8788.full.pdf)
> In 2014, researchers from Facebook and Cornell University conducted a study of emotional contagion based on a random sample of Facebook users over a one-week period in 2012. It caused a heated discussion on ethics, legal policy, and psychological test standard. 

YouTube's top creators are burning out and breaking down

    https://www.polygon.com/2018/6/1/17413542/burnout-mental-health-awareness-youtube-elle-mills-el-rubius-bobby-burns-pewdiepie

    https://www.tubefilter.com/2016/06/23/reverse-engineering-youtube-algorithm/

    https://www.tubefilter.com/2017/02/16/youtube-algorithm-reverse-engineering-part-ii/

    https://ai.google/research/pubs/pub45530

> A few articles on the YouTube's promotional algorithms depict an ecosystem of how the YouTube algorithm is impacting the life of human - the YouTube's top creators. The metric "Watchtime" is a combination of views, view duration, session starts, upload frequency, session duration, and session ends.

> ![alt text](Assets/youtube.png "DNN for Youtube Recommendation")

Can Mark Zuckerberg Fix Facebook Before It Breaks Democracy?

    https://www.newyorker.com/magazine/2018/09/17/can-mark-zuckerberg-fix-facebook-before-it-breaks-democracy

    https://www.theguardian.com/news/2017/may/21/facebook-moderators-quick-guide-job-challenges 

> If we look into the driving force behind a large-scale algorithmic system as large as Facebook, there are multiple factors. 

> Zuckerberg, the CEO of Facebook, and his executives believe that even if people criticized your decisions, they would eventually come around. He also holds his own principles like he sought to avoid banning users. 

#### Notes
The over-arching questions I am interested in 
1. How algorithm, as an invention of humans, can be used to change humans mentally and physically?
2. How is algorithm transparency being defined in policy and law in different countries/regions in the world?


